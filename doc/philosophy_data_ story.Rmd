---
title: "A Philosophy Data Story"
output: html_notebook
---
```{r warning=FALSE}
library(dplyr)
library(ggplot2)
library(tm)
library(tidytext)
library(knitr)
library(sentimentr)
library(wordcloud)
```

## Section 1. Brief Information of Data
```{r}
phi_data <- read.csv('../../philosophy_data.csv')
head(phi_data)
```

```{r}
colnames(phi_data)
```
In this philosophy story, only columns *title*, *author*, *school*, *original_publication_date*, *sentence_length*, *sentence_lowered* and *lemmatized_str* are used. 

A reordered dataset according to the original publication date is provided. 
```{r}
new_phi_data <- phi_data[order(phi_data$original_publication_date),c("title", "author", "school", "original_publication_date", "sentence_length", "sentence_lowered", "lemmatized_str")]
```

## Section 2. Sentiment Analysis
In this part, sentiment score is used for sentence analysis.\
A score of **1** indicates positive sentiment, a score of **-1** indicates negative sentiment, and a score of **0** indicates neutral sentiment.\
The mean sentiment score of each book is calculated.
```{r, warning=FALSE}
list_title <- c()
list_sentimentscore <- c()
for (i in unique(new_phi_data$title)){
  list_title <- append(list_title, i)
  tem_df <- new_phi_data[new_phi_data$title == i,]
  tem_s <- sentiment(tem_df$sentence_lowered)
  sentiment_score <- mean(tem_s[tem_s$sentence_id==1,]$sentiment)
  list_sentimentscore <- append(list_sentimentscore, sentiment_score)
}
```

```{r}
# Create a new dataframe -title_score- for title and mean score.
title_score <- data.frame(list_title, list_sentimentscore)
colnames(title_score) <- c("title", "sentiment_score")
head(title_score)
```
```{r}
# Get unique values of (title, author, school, original_publication_date) in the new dataframe.
# Join the *title_score* and *unique_phi* together by column *title*. 
unique_phi <- unique(new_phi_data[,c("title", "author", "school", "original_publication_date")])
phi_data_score <- merge(x=title_score, y=unique_phi, by="title")
head(phi_data_score)
```

```{r}
# Plot sentiment score of books against their original publication date, also label their schools.
ggplot(data=phi_data_score)+
  geom_point(mapping=aes(x=original_publication_date, y=sentiment_score, color=school))+
  xlab("original publication date")+
  ylab("mean sentiment score")+
  ggtitle("Sentiment Score of Books")+
  theme(plot.title = element_text(hjust = 0.5))
```
From the graph, only 4 of the books were not published from 1500 to 2000.

```{r}
# Books with 2 lowest sentiment scores.
phi_data_score[order(phi_data_score$sentiment_score),][1:2,]$title
```

```{r}
# Book with highest sentiment score.
phi_data_score[order(phi_data_score$sentiment_score, decreasing = TRUE),][1,]$title
```
We see that **History of Madness** and **Women, Race, And Class** have lowest sentiment scores and **Discourse On Method** has highest sentiment score.
```{r warning=FALSE}
# A closer look from 1500 to 2000. 
ggplot(data=phi_data_score)+
  geom_point(mapping=aes(x=original_publication_date, y=sentiment_score, color=school))+
  xlab("original publication date")+
  ylab("mean sentiment score")+
  ggtitle("Sentiment Score of Books from 1500 to 2000")+
  xlim(c(1500,2000))+
  geom_text(x=1637,y=0.175, label="Discourse On Method", color="red", size=3)+
  geom_text(x=1961,y=-0.055, label="History Of Madness", color="red", size=3)+
  geom_text(x=1951,y=-0.035, label="Women, Race, And Class", color="red", size=3)+
  theme(plot.title = element_text(hjust = 0.5))
```
From the closer look, books of **german_idealism** are often with higher sentiment scores and books of **continental** are often with lower sentiment scores.\
These three books and two schools will be analyzed further. 

## Section 3. Word Cloud Analysis
The text mining method of word cloud enables us to highlight the most frequently used keywords in the text.

### 3.1 History Of Madness
```{r}
# Load the text data as a Corpus.
hm <- phi_data%>%filter(title=="History Of Madness")
hm_lemma <- iconv(hm$lemmatized_str)
hm_lemma <- Corpus(VectorSource(hm_lemma))
```

```{r warning=FALSE}
# Clean data: remove punctuation, some words, numbers, stop words and white space.
hm_lemma <- hm_lemma%>%
  tm_map(removePunctuation)%>%
  tm_map(removeWords, c("PRON", "one", "can", "must", "also", "may"))%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords("english"))%>%
  tm_map(stripWhitespace)
```

```{r}
# Construct a document matrix - a table containing the frequency of words.
hm_dtm <- TermDocumentMatrix(hm_lemma)
hm_tidy <- tidy(hm_dtm)
hm_overall <- summarise(group_by(hm_tidy, term), sum(count))
```

```{r warning = FALSE}
wordcloud(hm_overall$term, hm_overall$`sum(count)`,
          scale=c(5,0.5),
          max.words=100,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          random.color=FALSE,
          colors=brewer.pal(9,"Dark2"))
```

The book **History of Madness** talks about the origin and earlier development of madness. From the word cloud graph above, words like **confinement, madness, insane, madman, delirium** refer how people with madness are treated. Most of the words here are negative, which is in line with the sentiment score of the book. 

### 3.2 Women, Race, And Class
```{r}
wrc <- phi_data%>%filter(title=="Women, Race, And Class")
wrc_lemma <- iconv(wrc$lemmatized_str)
wrc_lemma <- Corpus(VectorSource(wrc_lemma))
```

```{r warning=FALSE}
wrc_lemma <- wrc_lemma%>%
  tm_map(removePunctuation)%>% 
  tm_map(removeWords, c("PRON", "one", "can", "must", "also", "may"))%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords("english"))%>%
  tm_map(stripWhitespace)
```

```{r}
wrc_dtm <- TermDocumentMatrix(wrc_lemma)
wrc_tidy <- tidy(wrc_dtm)
wrc_overall <- summarise(group_by(wrc_tidy, term), sum(count))
```

```{r warning = FALSE}
wordcloud(wrc_overall$term, wrc_overall$`sum(count)`,
          scale=c(5,0.5),
          max.words=100,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          random.color=FALSE,
          colors=brewer.pal(9,"Dark2"))
```
The book **Women, Race, And Class** contains Marxist feminist analysis of gender, race and class. Words like **woman, man, sexual** imply that this book talks mainly about genders. Also, based on genders, topics about races(black, white) are also discussed. This book also talks about slavery and the potential economic effect it has. 

### 3.3 Discourse On Method
```{r}
dm <- phi_data%>%filter(title=="Discourse On Method")
dm_lemma <- iconv(dm$lemmatized_str)
dm_lemma <- Corpus(VectorSource(dm_lemma))
```

```{r warning=FALSE}
dm_lemma <- dm_lemma%>%
  tm_map(removePunctuation)%>%
  tm_map(removeWords, c("PRON", "one", "can", "must", "also", "may"))%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords("english"))%>%
  tm_map(stripWhitespace)
```

```{r}
dm_dtm <- TermDocumentMatrix(dm_lemma)
dm_tidy <- tidy(dm_dtm)
dm_overall <- summarise(group_by(dm_tidy, term), sum(count))
```

```{r warning = FALSE}
wordcloud(dm_overall$term, dm_overall$`sum(count)`,
          scale=c(5,0.5),
          max.words=300,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          random.color=FALSE,
          colors=brewer.pal(9,"Dark2"))
```
The book **Discourse On Method**, from school of rationalism, is important to the development of natural sciences. The book aims to talk about four methods to solve problems in nature. From the word cloud graph above, words like **nature, truth, reason** also point out the main ideas.

### 3.4 School of german_idealism
Books from school of german_idealism are with higher sentiment scores.
```{r}
germ <- phi_data%>%filter(school=="german_idealism")
germ_lemma <- iconv(germ$lemmatized_str)
germ_lemma <- Corpus(VectorSource(germ_lemma))
```

```{r warning=FALSE}
germ_lemma <- germ_lemma%>%
  tm_map(removePunctuation)%>%
  tm_map(removeWords, c("PRON", "one", "can", "must", "also", "may"))%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords("english"))%>%
  tm_map(stripWhitespace)
```

```{r}
germ_dtm <- TermDocumentMatrix(germ_lemma)
germ_tidy <- tidy(germ_dtm)
germ_overall <- summarise(group_by(germ_tidy, term), sum(count))
```

```{r warning = FALSE}
wordcloud(germ_overall$term, germ_overall$`sum(count)`,
          scale=c(5,0.5),
          max.words=300,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          random.color=FALSE,
          colors=brewer.pal(9,"Dark2"))
```
The philosophical meaning of idealism are those properties we discover in objects are dependent on the way that those objects appear to us, as perceiving subjects.\
From the word cloud graph above, words like **concept, self** also illustrate this.

### 3.5 School of continental
Books from school of continental are with lower sentiment scores.
```{r}
cont_sch <- phi_data%>%filter(school=="continental")
cont_sch_lemma <- iconv(cont_sch$lemmatized_str)
cont_sch_lemma <- Corpus(VectorSource(cont_sch_lemma))
```

```{r warning=FALSE}
cont_sch_lemma <- cont_sch_lemma%>%
  tm_map(removePunctuation)%>%
  tm_map(removeWords, c("PRON", "one", "can", "must", "also", "may"))%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords("english"))%>%
  tm_map(stripWhitespace)
```

```{r}
cont_sch_dtm <- TermDocumentMatrix(cont_sch_lemma)
cont_sch_tidy <- tidy(cont_sch_dtm)
cont_sch_overall <- summarise(group_by(cont_sch_tidy, term), sum(count))
```

```{r warning = FALSE}
wordcloud(cont_sch_overall$term, cont_sch_overall$`sum(count)`,
          scale=c(5,0.5),
          max.words=300,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          random.color=FALSE,
          colors=brewer.pal(9,"Dark2"))
```
The school of continental talks more about difference and fight. Words like **madness, difference, fact** illustrate that books from this school focus more on negative side of society.

## Section 4. Sentence length Analysis
In this section, sentence length is more focused on. 
```{r}
ggplot(data=new_phi_data)+
  geom_boxplot(mapping=aes(x=school, y=sentence_length, color=school))+
  theme(axis.text.x=element_text(angle=90))+
  ggtitle("Boxplot of Sentence Length in Each School")+
  theme(plot.title = element_text(hjust = 0.5))
```
There are always outliers of sentence length in each school.
```{r}
# Calculate mean sentence of each book and combine it with phi_data_score.
title_length <- 
  new_phi_data %>% 
  group_by(title)%>%
  summarise(mean_sent_length=mean(sentence_length))
phi_data_score_length <- merge(phi_data_score, title_length, by="title")
```

```{r warning=FALSE}
ggplot(data=phi_data_score_length)+
  geom_point(mapping=aes(x=original_publication_date, y=mean_sent_length, color=school))+
  xlab("original publication date")+
  ylab("mean sentence length")+
  ggtitle("Sentence Length of Books")+
  theme(plot.title = element_text(hjust = 0.5))
```
The mean sentence length of books from the same school tends to be together.
```{r warning=FALSE}
ggplot(data=phi_data_score_length)+
  geom_point(mapping=aes(x=original_publication_date, y=mean_sent_length, color=school))+
  xlab("original publication date")+
  ylab("mean sentence length")+
  ggtitle("Sentence Length of Books from 1500 to 2000")+
  xlim(c(1500, 2000))+
  theme(plot.title = element_text(hjust = 0.5))
```
A closer look at books shows that for example, books from german_idealism, have similar sentence length. In section 3, books from the same school tend to share similar sentiment scores. Will there be any relation between sentiment scores and sentence length?

```{r warning=FALSE}
ggplot(data=phi_data_score_length, mapping = aes(x=mean_sent_length, y=sentiment_score))+
  geom_point(mapping=aes(color=school))+
  geom_smooth(method="lm", se=FALSE)+
  xlab("Mean Sentence Length")+
  ylab("Sentiment Score")+
  ggtitle("Sentiment Score v. Mean Sentence Length of Books")
```
From the linear regression line in the graph, there seems to be a positive relation.
```{r}
lm <- lm(sentiment_score~mean_sent_length, data=phi_data_score_length)
summary(lm)
```
The result of linear regression shows that there is a significant positive relation between sentiment score and mean sentence length, which means, book with longer sentences tends to be more positive.

## The End.






